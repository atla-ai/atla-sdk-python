{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_spCXMT3r128"
   },
   "source": [
    "# Choose a base model for your AI Agent using Atla x Langfuse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31K7AlAQrA0f"
   },
   "source": [
    "This notebook demonstrates how to evaluate function calling capabilities across different models using **Atla Selene for evaluation** and **Langfuse for experiment observability**. If you'd like a visual walkthrough, check out our [demo video](https://youtu.be/0lenKLgn1p8).\n",
    "\n",
    "We compare the performance of various models (o1-mini, o3-mini, and gpt-4o) on function calling tasks using the [Salesforce ShareGPT dataset](https://huggingface.co/datasets/arcee-ai/agent-data/viewer/default/train?f%5Bdataset%5D%5Bvalue%5D=%27glaive-function-calling-v2-extended%27&sql=SELECT+*%0AFROM+train%0AWHERE+dataset+%3D+%27salesforce_sharegpt%27%0ALIMIT+10%3B&views%5B%5D=train).\n",
    "\n",
    "The notebook uploads the dataset to Langfuse and sets up experiment runs on different models, where these are automatically evaluated by Selene.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "- An Atla account - you can sign up for free [here](https://www.atla-ai.com/sign-up)\n",
    "- A Langfuse account - you can sign up for free [here](https://cloud.langfuse.com/auth/sign-up)\n",
    "- An OpenAI API key - you can sign up for free [here](https://platform.openai.com/signup)\n",
    "\n",
    "**Get started**\n",
    "\n",
    "1. Follow the steps below in **Setup Atla on Langfuse**.\n",
    "2. Set your Langfuse + OpenAI API keys.\n",
    "3. Run the rest of the functions to run experiments on performance across the three OpenAI models. Selene will score the outputs against the ground truths from the dataset.\n",
    "4. Easily compare model outputs and assess average scores in your Langfuse Cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSh3ZbhjlqAA"
   },
   "source": [
    "## Setup Atla on Langfuse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2rVF81u03cg"
   },
   "source": [
    "Navigate to your project on [cloud.langfuse.com](cloud.langfuse.com):\n",
    "\n",
    "<br>\n",
    "\n",
    "**Add your Atla API key to your Langfuse project:**\n",
    "\n",
    "1. Head to **Settings** → **LLM Connections** and select **+** **Add new LLM API key.**\n",
    "2. Set `atla` as the **Provider name** and select `atla` from the **LLM adapter** dropdown .\n",
    "3. The API Base URL will automatically be filled in. Paste your Atla API key beginning with “pk-…” into the **API Key** field.\n",
    "4. Leave **Enable default models** on.\n",
    "5. Click **Save new LLM API key.**\n",
    "\n",
    "![alt text](https://atla-ai.notion.site/image/attachment%3Aed7c7d92-b0bf-464f-9f43-83df6de65a5e%3Aimage.png?table=block&id=1bc309d1-7745-80fd-9f2d-cdd40f3005cf&spaceId=f08e6e70-73af-4363-9621-90e906b92ebc&width=2000&userId=&cache=v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MR1Rms-uE1jg"
   },
   "source": [
    "**Add an LLM-as-a-Judge template**\n",
    "\n",
    "1. Head to **Evaluation → LLM-as-a-Judge** in your sidebar and select **Templates**\n",
    "2. Click **+ New Template**\n",
    "3. Select atla as the Model Provider and choose atla-selene as the Model name\n",
    "4. Let’s evaluate the function calling ability of a model - name your template `function_calling` and paste in the following prompt:\n",
    "\n",
    "```\n",
    "Evaluate whether the model accurately selects the appropriate function(s) from the available options with a binary score of 0 or 1, comparing against the provided ground truth.\n",
    "\n",
    "Scoring Criteria:\n",
    "1: The model selection matches the ground truth—selected the correct function(s) using the proper tool call syntax.\n",
    "0: The model selection does not match the ground truth—selected incorrect functions, missed required functions, or used significantly different parameters.\n",
    "\n",
    "Instruction: {{input}}\n",
    "Ground Truth: {{expected_output}}\n",
    "Response: {{output}}\n",
    "```\n",
    "\n",
    "5. Adjust the prompt under **Reasoning** to tune Selene’s evaluation critique to your liking - we use \"One sentence reasoning for the score\"\n",
    "\n",
    "6. Adjust the prompt under **Score** to \"Score 0 or 1\" in alignment with our eval prompt and hit **Save**\n",
    "\n",
    "![alt text](https://atla-ai.notion.site/image/attachment%3A0078240d-4138-4b4c-a00e-075304065051%3Aimage.png?table=block&id=1ba309d1-7745-80fa-bc58-d43390728b0c&spaceId=f08e6e70-73af-4363-9621-90e906b92ebc&width=2000&userId=&cache=v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OSyZivbsE4LR"
   },
   "source": [
    "**Add a new Evaluator configuration:**\n",
    "\n",
    "1. Head to **Evaluation → LLM-as-a-Judge** in your sidebar and select **Evaluators**\n",
    "2. Click **+ New evaluator**\n",
    "3. Select the template `function_calling`  you just created\n",
    "4. Select Dataset as the **Target object** and make sure the Evaluator runs on **New dataset items**\n",
    "5. Configure the **Variable mapping** for your evaluator - this ensures that the correct parts of your traces get evaluated.\n",
    "    - `{{input}}` can be mapped to **Dataset item → Input**\n",
    "    - `{{expected_output}}` can be mapped to **Dataset item → Expected output**\n",
    "    - `{{output}}` can be mapped to **Trace → Output**\n",
    "6. Click **Save**\n",
    "\n",
    "![alt text](https://atla-ai.notion.site/image/attachment%3Af49c428d-d8ef-44ed-9a87-3d6936fe1252%3Aimage.png?table=block&id=1ba309d1-7745-80af-b04c-c558c7f8225f&spaceId=f08e6e70-73af-4363-9621-90e906b92ebc&width=2000&userId=&cache=v2)\n",
    "\n",
    "> You can set a sampling rate such that a % of the dataset is evaluated. For the purposes of this demonstration, we want to evaluate every trace so keep the sampling rate at 100%!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSSEEPlmW9bz"
   },
   "source": [
    "## Set Langfuse + OpenAI API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1742816030988,
     "user": {
      "displayName": "Kyle Dai",
      "userId": "04739623040311656672"
     },
     "user_tz": 0
    },
    "id": "D9gBPNJjC8Qm"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"\" # Your public key\n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"\" # Your secret key\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\" # Your OpenAI API key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNUUhfMB1AXI"
   },
   "source": [
    "## Setup experiment runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ApIVYqfWXFmi"
   },
   "source": [
    "### Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 8839,
     "status": "ok",
     "timestamp": 1742816039831,
     "user": {
      "displayName": "Kyle Dai",
      "userId": "04739623040311656672"
     },
     "user_tz": 0
    },
    "id": "E1ISYlFCXEs4"
   },
   "outputs": [],
   "source": [
    "pip install -qU datasets langfuse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nkDPRb7G1chT"
   },
   "source": [
    "### Upload dataset to Langfuse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DsWp-3OzQf3u"
   },
   "source": [
    "We processes data from the [Salesforce ShareGPT dataset](https://huggingface.co/datasets/arcee-ai/agent-data/viewer/default/train?f%5Bdataset%5D%5Bvalue%5D=%27glaive-function-calling-v2-extended%27&sql=SELECT+*%0AFROM+train%0AWHERE+dataset+%3D+%27salesforce_sharegpt%27%0ALIMIT+10%3B&views%5B%5D=train), extracting system prompts (that define the list of functions available), user queries, and the expected response.\n",
    "\n",
    "This data includes:\n",
    "\n",
    "1. `system_prompt` - Defines the AI's role as a function calling model, provides available functions in a <tools> XML format, and specifies the expected response format using <tool_call> tags.\n",
    "<br>\n",
    "\n",
    "2. `input` - A human query that asks the model to perform some task using the available functions.\n",
    "<br>\n",
    "\n",
    "3. `expected_output` - The expected model's response that includes one or more function calls in the specified XML format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20734,
     "status": "ok",
     "timestamp": 1742816060575,
     "user": {
      "displayName": "Kyle Dai",
      "userId": "04739623040311656672"
     },
     "user_tz": 0
    },
    "id": "pbAqPxAG-EJ8",
    "outputId": "a39c2250-0dd7-4153-d10d-24bf5dccc5d6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items after filtering: 10\n",
      "\n",
      "First item structure:\n",
      "{'conversations': [{'from': 'system', 'value': 'You are a function calling AI model. You may call one or more functions to assist with the user query. Don\\'t make assumptions about what values to plug into function. The user may use the terms function calling or tool use interchangeably.\\n\\nHere are the available functions:\\n<tools>[{\"name\": \"live_giveaways_by_type\", \"description\": \"Retrieve live giveaways from the GamerPower API based on the specified type.\", \"parameters\": {\"type\": {\"description\": \"The type of giveaways to retrieve (e.g., game, loot, beta).\", \"type\": \"str\", \"default\": \"game\"}}}]</tools>\\n\\nFor each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags in the format:\\n<tool_call>{\"tool_name\": <function-name>, \"tool_arguments\": <args-dict>}</tool_call>'}, {'from': 'human', 'value': 'Where can I find live giveaways for beta access and games?'}, {'from': 'gpt', 'value': \"<tool_call>{'tool_name': 'live_giveaways_by_type', 'tool_arguments': {'type': 'beta'}}</tool_call>\\n<tool_call>{'tool_name': 'live_giveaways_by_type', 'tool_arguments': {'type': 'game'}}</tool_call>\"}], 'dataset': 'salesforce_sharegpt'}\n",
      "\n",
      "Processing item with conversations: [{'from': 'system', 'value': 'You are a function calling AI model. You may call one or more functions to assist with the user query. Don\\'t make assumptions about what values to plug into function. The user may use the terms function calling or tool use interchangeably.\\n\\nHere are the available functions:\\n<tools>[{\"name\": \"live_giveaways_by_type\", \"description\": \"Retrieve live giveaways from the GamerPower API based on the specified type.\", \"parameters\": {\"type\": {\"description\": \"The type of giveaways to retrieve (e.g., game, loot, beta).\", \"type\": \"str\", \"default\": \"game\"}}}]</tools>\\n\\nFor each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags in the format:\\n<tool_call>{\"tool_name\": <function-name>, \"tool_arguments\": <args-dict>}</tool_call>'}, {'from': 'human', 'value': 'Where can I find live giveaways for beta access and games?'}, {'from': 'gpt', 'value': \"<tool_call>{'tool_name': 'live_giveaways_by_type', 'tool_arguments': {'type': 'beta'}}</tool_call>\\n<tool_call>{'tool_name': 'live_giveaways_by_type', 'tool_arguments': {'type': 'game'}}</tool_call>\"}]\n",
      "\n",
      "Processing item with conversations: [{'from': 'system', 'value': 'You are a function calling AI model. You may call one or more functions to assist with the user query. Don\\'t make assumptions about what values to plug into function. The user may use the terms function calling or tool use interchangeably.\\n\\nHere are the available functions:\\n<tools>[{\"name\": \"peers\", \"description\": \"Retrieves a list of company peers given a stock symbol.\", \"parameters\": {\"symbol\": {\"description\": \"The stock symbol for the company.\", \"type\": \"str\", \"default\": \"\"}}}, {\"name\": \"web_chain_details\", \"description\": \"python\", \"parameters\": {\"chain_slug\": {\"description\": \"The slug identifier for the blockchain (e.g., \\'ethereum\\' for Ethereum mainnet).\", \"type\": \"str\", \"default\": \"ethereum\"}}}]</tools>\\n\\nFor each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags in the format:\\n<tool_call>{\"tool_name\": <function-name>, \"tool_arguments\": <args-dict>}</tool_call>'}, {'from': 'human', 'value': \"I need to understand the details of the Ethereum blockchain for my cryptocurrency project. Can you fetch the details for 'ethereum'?\"}, {'from': 'gpt', 'value': \"<tool_call>{'tool_name': 'web_chain_details', 'tool_arguments': {'chain_slug': 'ethereum'}}</tool_call>\"}]\n",
      "\n",
      "Processing item with conversations: [{'from': 'system', 'value': 'You are a function calling AI model. You may call one or more functions to assist with the user query. Don\\'t make assumptions about what values to plug into function. The user may use the terms function calling or tool use interchangeably.\\n\\nHere are the available functions:\\n<tools>[{\"name\": \"t3ma\", \"description\": \"Fetches the Triple Exponential Moving Average (T3MA) for a given financial instrument.\", \"parameters\": {\"symbol\": {\"description\": \"Instrument symbol, which can be any equity, index, ETF, forex, or cryptocurrency (e.g., \\'AAPL\\', \\'EUR/USD\\', \\'ETH/BTC\\').\", \"type\": \"str\", \"default\": \"AAPL\"}, \"interval\": {\"description\": \"Interval between two consecutive points in the time series. Supported intervals include \\'1min\\', \\'5min\\', \\'15min\\', \\'30min\\', \\'45min\\', \\'1h\\', \\'2h\\', \\'4h\\', \\'1day\\', \\'1week\\', and \\'1month\\'.\", \"type\": \"str\", \"default\": \"1min\"}, \"format\": {\"description\": \"Format of the response data, either \\'CSV\\' or \\'JSON\\'. Default is \\'json\\'.\", \"type\": \"str, optional\", \"default\": \"json\"}, \"v_factor\": {\"description\": \"Volume factor used in the calculation of the T3MA.\", \"type\": \"int, optional\", \"default\": 0.7}, \"series_type\": {\"description\": \"Type of series to use in the calculation. Supported values are \\'open\\', \\'high\\', \\'low\\', and \\'close\\'. Default is \\'close\\'.\", \"type\": \"str, optional\", \"default\": \"close\"}, \"outputsize\": {\"description\": \"Number of data points to return. Default is 30.\", \"type\": \"int, optional\", \"default\": 30}, \"time_period\": {\"description\": \"Number of periods over which to calculate the T3MA. Default is 9.\", \"type\": \"int, optional\", \"default\": 9}}}, {\"name\": \"stock_v2_get_profile\", \"description\": \"Retrieves the company profile information for a given performance ID using the RapidAPI Morning Star service.\", \"parameters\": {\"performanceid\": {\"description\": \"The performance ID of the stock, obtained from endpoints such as /auto-complete, /get-summary, or /get-movers.\", \"type\": \"str\", \"default\": \"0P0000OQN8\"}}}]</tools>\\n\\nFor each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags in the format:\\n<tool_call>{\"tool_name\": <function-name>, \"tool_arguments\": <args-dict>}</tool_call>'}, {'from': 'human', 'value': \"What is the T3MA for 'ETH/BTC' using a 1h interval and a time period of 14?\"}, {'from': 'gpt', 'value': \"<tool_call>{'tool_name': 't3ma', 'tool_arguments': {'symbol': 'ETH/BTC', 'interval': '1h', 'time_period': 14}}</tool_call>\"}]\n",
      "\n",
      "Processing item with conversations: [{'from': 'system', 'value': 'You are a function calling AI model. You may call one or more functions to assist with the user query. Don\\'t make assumptions about what values to plug into function. The user may use the terms function calling or tool use interchangeably.\\n\\nHere are the available functions:\\n<tools>[{\"name\": \"get_animes\", \"description\": \"Retrieves a list of animes based on specified search criteria and filters from the RapidAPI Anime API.\", \"parameters\": {\"year_greater\": {\"description\": \"Find animes released after the specified year.\", \"type\": \"int, optional\", \"default\": \"\"}, \"media_type\": {\"description\": \"Filter by media type (e.g., music, tv, ona, ova, movie, special).\", \"type\": \"str, optional\", \"default\": \"\"}, \"studio\": {\"description\": \"Filter by studio name.\", \"type\": \"str, optional\", \"default\": \"\"}, \"year_less\": {\"description\": \"Find animes released before the specified year.\", \"type\": \"int, optional\", \"default\": \"\"}, \"nsfw\": {\"description\": \"Include NSFW content if set.\", \"type\": \"str, optional\", \"default\": \"\"}, \"status\": {\"description\": \"Filter by anime status (e.g., currently_airing, finished_airing, not_yet_aired).\", \"type\": \"str, optional\", \"default\": \"\"}, \"limit\": {\"description\": \"Limit the number of results.\", \"type\": \"int, optional\", \"default\": \"\"}, \"q\": {\"description\": \"Search for animes by title in English or Japanese.\", \"type\": \"str, optional\", \"default\": \"\"}, \"genre\": {\"description\": \"Filter by genre.\", \"type\": \"str, optional\", \"default\": \"\"}, \"sort\": {\"description\": \"Specify sort order, True for ascending and False for descending.\", \"type\": \"bool, optional\", \"default\": \"\"}, \"offset\": {\"description\": \"Number of results to skip.\", \"type\": \"int, optional\", \"default\": \"\"}, \"season\": {\"description\": \"Filter by season.\", \"type\": \"str, optional\", \"default\": \"\"}, \"fields\": {\"description\": \"Specify the fields to return (e.g., id, title, main_picture, etc.).\", \"type\": \"str, optional\", \"default\": \"\"}, \"year_equal\": {\"description\": \"Filter by animes released in the specified year.\", \"type\": \"int, optional\", \"default\": \"\"}, \"source\": {\"description\": \"Filter by source material (e.g., manga, visual_novel, novel, etc.).\", \"type\": \"str, optional\", \"default\": \"\"}, \"order\": {\"description\": \"Order results by a specific field.\", \"type\": \"str, optional\", \"default\": \"\"}}}, {\"name\": \"list_titles\", \"description\": \"Fetches a listing of titles that match specified parameters from the Watchmode API.\", \"parameters\": {\"genres\": {\"description\": \"Filter results to only include certain genre(s). Pass in a single genre ID or multiple comma-separated IDs. Default is \\'4,9\\'.\", \"type\": \"str\", \"default\": \"4,9\"}, \"limit\": {\"description\": \"Set how many titles to return per page. Default and maximum is 250.\", \"type\": \"int\", \"default\": \"250\"}, \"source_ids\": {\"description\": \"Filter the results to titles available on specific sources by passing individual IDs or multiple comma-separated IDs. Default is \\'23,206\\'. Note: Only a single region can be set if this is populated.\", \"type\": \"str\", \"default\": \"23,206\"}, \"source_types\": {\"description\": \"Filter results to only include titles available on specific types of sources (e.g., subscription, free). Default is \\'sub,free\\'. Note: Only a single region can be set if this is populated.\", \"type\": \"str\", \"default\": \"sub,free\"}, \"types\": {\"description\": \"Filter results to only include titles available on specific types of sources (e.g., subscription, free). Default is \\'sub,free\\'. Note: Only a single region can be set if this is populated.\", \"type\": \"str\", \"default\": \"movie,tv_series\"}, \"regions\": {\"description\": \"Filter results to only include sources active in specific regions. Currently supported regions: US, GB, CA, AU. Default is \\'US\\'. Note: Only a single region can be set if source_ids or source_types are populated.\", \"type\": \"str\", \"default\": \"US\"}, \"sort_by\": {\"description\": \"Sort order of results. Possible values include: relevance_desc, relevance_asc, popularity_desc, popularity_asc, release_date_desc, release_date_asc, title_desc, title_asc. Default is \\'relevance_desc\\'.\", \"type\": \"str\", \"default\": \"relevance_desc\"}, \"page\": {\"description\": \"Set the page of results to return. Default is 1.\", \"type\": \"int\", \"default\": \"1\"}, \"network_ids\": {\"description\": \"Filter results to titles that originally aired on specific TV networks by passing individual IDs or multiple comma-separated IDs. Default is \\'1,8,12\\'.\", \"type\": \"str\", \"default\": \"1,8,12\"}, \"release_date_start\": {\"description\": \"Filter results to only include titles released on or after a specific date. Format: YYYYMMDD. Default is 20010101.\", \"type\": \"int\", \"default\": \"20010101\"}, \"release_date_end\": {\"description\": \"Filter results to only include titles released on or before a specific date. Format: YYYYMMDD. Default is 20201211.\", \"type\": \"int\", \"default\": \"20201211\"}}}]</tools>\\n\\nFor each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags in the format:\\n<tool_call>{\"tool_name\": <function-name>, \"tool_arguments\": <args-dict>}</tool_call>'}, {'from': 'human', 'value': \"List titles originally aired on networks '1' and '8', released after 2010, sorted by release date in descending order.\"}, {'from': 'gpt', 'value': \"<tool_call>{'tool_name': 'list_titles', 'tool_arguments': {'network_ids': '1,8', 'release_date_start': 20110101, 'sort_by': 'release_date_desc'}}</tool_call>\"}]\n",
      "\n",
      "Processing item with conversations: [{'from': 'system', 'value': 'You are a function calling AI model. You may call one or more functions to assist with the user query. Don\\'t make assumptions about what values to plug into function. The user may use the terms function calling or tool use interchangeably.\\n\\nHere are the available functions:\\n<tools>[{\"name\": \"stagecompetitorstandings\", \"description\": \"Retrieve the competitor standings for a specific Motorsport stage using the given stage ID.\", \"parameters\": {\"is_id\": {\"description\": \"The ID of the stage for which to retrieve competitor\\'s standings.\", \"type\": \"int\", \"default\": 203968}}}]</tools>\\n\\nFor each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags in the format:\\n<tool_call>{\"tool_name\": <function-name>, \"tool_arguments\": <args-dict>}</tool_call>'}, {'from': 'human', 'value': 'Fetch the competitor standings for the recently concluded stage 98765.'}, {'from': 'gpt', 'value': \"<tool_call>{'tool_name': 'stagecompetitorstandings', 'tool_arguments': {'is_id': 98765}}</tool_call>\"}]\n",
      "\n",
      "Processing item with conversations: [{'from': 'system', 'value': 'You are a function calling AI model. You may call one or more functions to assist with the user query. Don\\'t make assumptions about what values to plug into function. The user may use the terms function calling or tool use interchangeably.\\n\\nHere are the available functions:\\n<tools>[{\"name\": \"get_product\", \"description\": \"Fetches product details from an API using the given product ID.\", \"parameters\": {\"is_id\": {\"description\": \"The product ID for which to retrieve details.\", \"type\": \"int\", \"default\": \"\"}}}, {\"name\": \"product_id\", \"description\": \"Fetches product details from the AliExpress API using the provided product ID and optional parameters.\", \"parameters\": {\"is_id\": {\"description\": \"The ID of the product to fetch details for.\", \"type\": \"int\", \"default\": \"4000886597329\"}, \"locale\": {\"description\": \"The locale to be used for the request (e.g., \\'en_US\\').\", \"type\": \"str, optional\", \"default\": \"\"}, \"currency\": {\"description\": \"The currency for price conversion (e.g., \\'USD\\').\", \"type\": \"str, optional\", \"default\": \"\"}, \"country\": {\"description\": \"The country for regional adjustments (e.g., \\'US\\').\", \"type\": \"str, optional\", \"default\": \"\"}}}]</tools>\\n\\nFor each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags in the format:\\n<tool_call>{\"tool_name\": <function-name>, \"tool_arguments\": <args-dict>}</tool_call>'}, {'from': 'human', 'value': \"Fetch details for product 456789 with locale 'es_ES'.\"}, {'from': 'gpt', 'value': \"<tool_call>{'tool_name': 'product_id', 'tool_arguments': {'is_id': 456789, 'locale': 'es_ES'}}</tool_call>\"}]\n",
      "\n",
      "Processing item with conversations: [{'from': 'system', 'value': 'You are a function calling AI model. You may call one or more functions to assist with the user query. Don\\'t make assumptions about what values to plug into function. The user may use the terms function calling or tool use interchangeably.\\n\\nHere are the available functions:\\n<tools>[{\"name\": \"get_id\", \"description\": \"Fetches the ID of a movie based on the given search query from the RapidAPI similar movies service.\", \"parameters\": {\"q\": {\"description\": \"The search string for the movie title.\", \"type\": \"str\", \"default\": \"titanic\"}}}, {\"name\": \"search_torrents\", \"description\": \"Search for torrents based on given keywords using the RapidAPI service.\", \"parameters\": {\"keywords\": {\"description\": \"Keywords to search for torrents.\", \"type\": \"str\", \"default\": \"Meg 2 The Trench\"}, \"quantity\": {\"description\": \"Number of torrent results to return. Maximum value is 40.\", \"type\": \"int\", \"default\": \"40\"}, \"page\": {\"description\": \"Page number for paginated results. Defaults to 1.\", \"type\": \"int, optional\", \"default\": \"1\"}}}, {\"name\": \"basic_info\", \"description\": \"Fetches detailed information about a cast member such as name, profession, birth and death year, bio, poster, and best titles.\", \"parameters\": {\"peopleid\": {\"description\": \"The ID of the cast member whose details are to be fetched.\", \"type\": \"str\", \"default\": \"nm0000375\"}}}]</tools>\\n\\nFor each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags in the format:\\n<tool_call>{\"tool_name\": <function-name>, \"tool_arguments\": <args-dict>}</tool_call>'}, {'from': 'human', 'value': \"Identify the ID of 'Pulp Fiction' and search for torrents related to it.\"}, {'from': 'gpt', 'value': \"<tool_call>{'tool_name': 'get_id', 'tool_arguments': {'q': 'Pulp Fiction'}}</tool_call>\\n<tool_call>{'tool_name': 'search_torrents', 'tool_arguments': {'keywords': 'Pulp Fiction', 'quantity': 10}}</tool_call>\"}]\n",
      "\n",
      "Processing item with conversations: [{'from': 'system', 'value': 'You are a function calling AI model. You may call one or more functions to assist with the user query. Don\\'t make assumptions about what values to plug into function. The user may use the terms function calling or tool use interchangeably.\\n\\nHere are the available functions:\\n<tools>[{\"name\": \"time_zone_api\", \"description\": \"Fetches up-to-date time zone and local time information as JSON based on a given query parameter.\", \"parameters\": {\"q\": {\"description\": \"Query parameter to fetch time zone data.\", \"type\": \"str\", \"default\": \"\"}}}]</tools>\\n\\nFor each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags in the format:\\n<tool_call>{\"tool_name\": <function-name>, \"tool_arguments\": <args-dict>}</tool_call>'}, {'from': 'human', 'value': 'Can you find the time zone for a Canadian postal code G2J and a latitude-longitude pair of 48.8567,2.3508?'}, {'from': 'gpt', 'value': \"<tool_call>{'tool_name': 'time_zone_api', 'tool_arguments': {'q': 'G2J'}}</tool_call>\\n<tool_call>{'tool_name': 'time_zone_api', 'tool_arguments': {'q': '48.8567,2.3508'}}</tool_call>\"}]\n",
      "\n",
      "Processing item with conversations: [{'from': 'system', 'value': 'You are a function calling AI model. You may call one or more functions to assist with the user query. Don\\'t make assumptions about what values to plug into function. The user may use the terms function calling or tool use interchangeably.\\n\\nHere are the available functions:\\n<tools>[{\"name\": \"find_peak_element\", \"description\": \"Finds a peak element in a list of integers.\", \"parameters\": {\"nums\": {\"description\": \"The list of integers.\", \"type\": \"List[int]\"}}}, {\"name\": \"light_travel_time\", \"description\": \"Calculate the time taken for light to travel from one celestial body to another.\", \"parameters\": {\"distance_in_light_years\": {\"description\": \"The distance between the two celestial bodies in light years.\", \"type\": \"int\", \"default\": 299792458}, \"speed_of_light\": {\"description\": \"The speed of light in vacuum, in m/s. Default value is 299792458 m/s.\", \"type\": \"int\", \"default\": 299792458}}}]</tools>\\n\\nFor each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags in the format:\\n<tool_call>{\"tool_name\": <function-name>, \"tool_arguments\": <args-dict>}</tool_call>'}, {'from': 'human', 'value': 'Determine the peak of the sequence [44, 46, 48, 50, 52] and the light travel time for 25 light years.'}, {'from': 'gpt', 'value': \"<tool_call>{'tool_name': 'find_peak_element', 'tool_arguments': {'nums': [44, 46, 48, 50, 52]}}</tool_call>\\n<tool_call>{'tool_name': 'light_travel_time', 'tool_arguments': {'distance_in_light_years': 25}}</tool_call>\"}]\n",
      "\n",
      "Processing item with conversations: [{'from': 'system', 'value': 'You are a function calling AI model. You may call one or more functions to assist with the user query. Don\\'t make assumptions about what values to plug into function. The user may use the terms function calling or tool use interchangeably.\\n\\nHere are the available functions:\\n<tools>[{\"name\": \"availability\", \"description\": \"Checks if a given URL is archived and currently accessible in the Wayback Machine.\", \"parameters\": {\"url\": {\"description\": \"The URL to check for availability in the Wayback Machine.\", \"type\": \"str\", \"default\": \"http://mashape.com\"}, \"timestamp\": {\"description\": \"The timestamp to look up in Wayback. If not specified, the most recent available capture is returned. The format of the timestamp is 1-14 digits (YYYYMMDDhhmmss). Defaults to \\'20090101\\'.\", \"type\": \"str, optional\", \"default\": \"20090101\"}, \"callback\": {\"description\": \"An optional callback to produce a JSONP response. Defaults to None.\", \"type\": \"str, optional\", \"default\": \"\"}}}]</tools>\\n\\nFor each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags in the format:\\n<tool_call>{\"tool_name\": <function-name>, \"tool_arguments\": <args-dict>}</tool_call>'}, {'from': 'human', 'value': \"Is 'https://www.apple.com' available in the Wayback Machine on September 9, 2015?\"}, {'from': 'gpt', 'value': \"<tool_call>{'tool_name': 'availability', 'tool_arguments': {'url': 'https://www.apple.com', 'timestamp': '20150909'}}</tool_call>\"}]\n",
      "\n",
      "Processed 10 items\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\" # EU region; LANGFUSE_HOST=\"https://us.cloud.langfuse.com\"\n",
    "\n",
    "from datasets import load_dataset\n",
    "from langfuse import Langfuse\n",
    "\n",
    "langfuse = Langfuse()\n",
    "\n",
    "# Load and process data\n",
    "dataset = load_dataset(\"arcee-ai/agent-data\")\n",
    "salesforce_data = list(dataset['train'].filter(lambda x: x['dataset'] == \"salesforce_sharegpt\"))[:10]  # convert to list first\n",
    "\n",
    "print(\"Number of items after filtering:\", len(salesforce_data))\n",
    "print(\"\\nFirst item structure:\")\n",
    "print(salesforce_data[0])\n",
    "\n",
    "# Process conversations into the format we want\n",
    "processed_items = []\n",
    "\n",
    "for item in salesforce_data:\n",
    "    try:\n",
    "        conversations = item['conversations']\n",
    "\n",
    "        # Debug print\n",
    "        print(\"\\nProcessing item with conversations:\", conversations)\n",
    "\n",
    "        system_prompt = next((conv['value'] for conv in conversations if conv['from'] == 'system'), '')\n",
    "        human_input = next((conv['value'] for conv in conversations if conv['from'] == 'human'), '')\n",
    "        model_output = next((conv['value'] for conv in conversations if conv['from'] == 'gpt'), '')\n",
    "\n",
    "        if system_prompt and human_input and model_output:\n",
    "            processed_items.append({\n",
    "                \"input\": {\n",
    "                    \"system_prompt\": system_prompt,\n",
    "                    \"query\": human_input\n",
    "                },\n",
    "                \"expected_output\": model_output\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping malformed entry: {e}\")\n",
    "        print(f\"Item that caused error: {item}\")\n",
    "\n",
    "print(f\"\\nProcessed {len(processed_items)} items\")\n",
    "\n",
    "# Create the dataset\n",
    "langfuse.create_dataset(\n",
    "    name=\"salesforce_sharegpt\",\n",
    "    description=\"Function calling dataset from ArceeAI\"\n",
    ")\n",
    "\n",
    "# Upload items\n",
    "for item in processed_items:\n",
    "    langfuse.create_dataset_item(\n",
    "        dataset_name=\"salesforce_sharegpt\",\n",
    "        input=item[\"input\"],\n",
    "        expected_output=item[\"expected_output\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xT06q54G1xrF"
   },
   "source": [
    "### Define experiment runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_hCQn_mzQLA"
   },
   "source": [
    "We run the system prompt and user query through each model, and evaluate if the responses follow the proper tool call syntax (enclosed in <tool_call> tags) as defined in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1742816181760,
     "user": {
      "displayName": "Kyle Dai",
      "userId": "04739623040311656672"
     },
     "user_tz": 0
    },
    "id": "uk0Q7iZRUVY6"
   },
   "outputs": [],
   "source": [
    "from langfuse.openai import openai\n",
    "from langfuse.decorators import observe, langfuse_context\n",
    "import time\n",
    "\n",
    "@observe\n",
    "def run_function_calling(input, model_name):\n",
    "    # Models that support system messages\n",
    "    system_supported_models = [\"gpt-4\", \"gpt-4o\", \"gpt-3.5-turbo\"]\n",
    "\n",
    "    if model_name in system_supported_models:\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": input[\"system_prompt\"]},\n",
    "            {\"role\": \"user\", \"content\": input[\"query\"]}\n",
    "        ]\n",
    "    else:\n",
    "        # For models that don't support system messages (the o-series), combine them in the user prompt\n",
    "        combined_prompt = f\"{input['system_prompt']}\\n\\nUser query: {input['query']}\"\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": combined_prompt}\n",
    "        ]\n",
    "\n",
    "    completion = openai.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=messages\n",
    "    ).choices[0].message.content\n",
    "\n",
    "    return completion\n",
    "\n",
    "def run_experiment(experiment_name, model_name):\n",
    "    dataset = langfuse.get_dataset(\"salesforce_sharegpt\")\n",
    "\n",
    "    for idx, item in enumerate(dataset.items):\n",
    "        with item.observe(run_name=experiment_name) as trace_id:\n",
    "            # Run application with the specific model\n",
    "            output = run_function_calling(item.input, model_name)\n",
    "\n",
    "        # Add a delay between requests to avoid rate limits\n",
    "        if idx < len(dataset.items) - 1:\n",
    "            time.sleep(2)  # 2 second delay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bk8EEql-oSOB"
   },
   "source": [
    "## Run experiments over different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 155798,
     "status": "ok",
     "timestamp": 1742816348597,
     "user": {
      "displayName": "Kyle Dai",
      "userId": "04739623040311656672"
     },
     "user_tz": 0
    },
    "id": "TwdmeVbNoVFq"
   },
   "outputs": [],
   "source": [
    "# Run experiments with different models\n",
    "models = [\"o1-mini\", \"o3-mini\", \"gpt-4o\"]\n",
    "for model in models:\n",
    "    run_experiment(f\"function_calling_{model}\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yjNYNUUdEWDq"
   },
   "source": [
    "## Analyze results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4UfNT8DO5yb"
   },
   "source": [
    "<br>\n",
    "\n",
    "After the experiments with the different models finish running, head to **Datasets** in your sidebar and click on `salesforce_sharegpt` .\n",
    "\n",
    "<br>\n",
    "\n",
    "####**High-level model comparison**\n",
    "\n",
    "- You will see **Latency (s)** and **Average Total Cost ($)** graphs by default.\n",
    "- Add **Charts → Scores → Function_calling (Eval)** to see the average Selene scores for `function_calling`.\n",
    "\n",
    "  ![alt text](https://atla-ai.notion.site/image/attachment%3Aecd25ea4-86ed-4534-a647-5b39391e0b35%3Aimage.png?table=block&id=1bd309d1-7745-8012-b2eb-f4b07f9d2a5b&spaceId=f08e6e70-73af-4363-9621-90e906b92ebc&width=2000&userId=&cache=v2)\n",
    "\n",
    "Based on our limited test set of 10 samples, it seems the reasoning models are more suited to our agentic task!\n",
    "\n",
    "####**Fine-grained model comparison**\n",
    "\n",
    "- Select the three experiment runs and click **Actions (3 selected) → Compare**\n",
    "\n",
    "  ![alt text](https://atla-ai.notion.site/image/attachment%3Aecd25ea4-86ed-4534-a647-5b39391e0b35%3Aimage.png?table=block&id=1bd309d1-7745-8012-b2eb-f4b07f9d2a5b&spaceId=f08e6e70-73af-4363-9621-90e906b92ebc&width=2000&userId=&cache=v2)\n",
    "\n",
    "\n",
    "- In the comparison screen, we can inspect cases where certain models fail vs. others—highlighted by a `# Function_calling (Eval)` score of 0 in the cell.\n",
    "\n",
    "  ![alt text](https://atla-ai.notion.site/image/attachment%3Aeb428c05-cac0-46de-ba69-bcfc389ae1a6%3Aimage.png?table=block&id=1c0309d1-7745-8058-b75b-fa6f963f2979&spaceId=f08e6e70-73af-4363-9621-90e906b92ebc&width=2000&userId=&cache=v2)\n",
    "\n",
    "####**Next steps**\n",
    "\n",
    "Now that you've analyzed the models' performance, consider setting up additional Evaluators to measure other metrics that matter to your specific use case. If you have a collection of test user queries, upload this dataset and run comparative tests across different models."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
